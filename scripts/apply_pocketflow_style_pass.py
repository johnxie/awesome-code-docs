#!/usr/bin/env python3
"""Apply PocketFlow-style documentation enrichment across tutorial docs.

This pass updates tutorial index and chapter markdown files to improve:
- beginner-friendly framing
- explicit "problem" and "under the hood" sections
- source-driven references
- chapter cross-navigation

The pass is idempotent by checking for heading presence before insertion.
"""

from __future__ import annotations

import argparse
import re
from pathlib import Path

INDEX_NAME = "index.md"
NUMBERED_FILE_RE = re.compile(r"^([0-9]{2,})[-_].+\.md$")
LINK_RE = re.compile(r"\[([^\]]+)\]\(([^)]+)\)")
GEN_FOOTER = (
    "*Generated by [AI Codebase Knowledge Builder]"
    "(https://github.com/The-Pocket/Tutorial-Codebase-Knowledge)*"
)


def read_text(path: Path) -> str:
    return path.read_text(encoding="utf-8", errors="ignore")


def write_text(path: Path, text: str) -> None:
    path.write_text(text, encoding="utf-8")


def first_h1(markdown: str) -> str:
    for line in markdown.splitlines():
        if line.startswith("# "):
            return line[2:].strip()
    return ""


def slug_phrase(value: str) -> str:
    return value.replace("-", " ").replace("_", " ").strip()


def chapter_records(tutorial_dir: Path) -> list[tuple[int, str, Path]]:
    records: list[tuple[int, str, Path]] = []
    for path in tutorial_dir.glob("*.md"):
        if path.name == INDEX_NAME:
            continue
        match = NUMBERED_FILE_RE.match(path.name)
        if not match:
            continue
        records.append((int(match.group(1)), path.name, path))
    records.sort(key=lambda x: (x[0], x[1]))
    return records


def section_body(markdown: str, heading: str) -> str:
    lines = markdown.splitlines()
    start = None
    for i, line in enumerate(lines):
        if line.strip() == heading:
            start = i + 1
            break
    if start is None:
        return ""
    end = len(lines)
    for j in range(start, len(lines)):
        if lines[j].startswith("## "):
            end = j
            break
    return "\n".join(lines[start:end]).strip()


def extract_links_from_heading(markdown: str, heading: str, limit: int) -> list[tuple[str, str]]:
    chunk = section_body(markdown, heading)
    if not chunk:
        return []
    out: list[tuple[str, str]] = []
    seen: set[str] = set()
    for label, url in LINK_RE.findall(chunk):
        label = label.strip()
        url = url.strip()
        if url in seen:
            continue
        seen.add(url)
        out.append((label, url))
        if len(out) >= limit:
            break
    return out


def extract_github_links(markdown: str, limit: int) -> list[tuple[str, str]]:
    out: list[tuple[str, str]] = []
    seen: set[str] = set()
    for label, url in LINK_RE.findall(markdown):
        if "github.com" not in url:
            continue
        if url in seen:
            continue
        seen.add(url)
        out.append((label.strip() or "GitHub", url.strip()))
        if len(out) >= limit:
            break
    return out


def ensure_index_chapter_map(
    index_text: str,
    tutorial_dir: Path,
    chapter_meta: list[tuple[int, str, Path]],
) -> tuple[str, bool]:
    if "## Full Chapter Map" in index_text:
        return index_text, False
    if not chapter_meta:
        return index_text, False

    lines = ["## Full Chapter Map", ""]
    for num, filename, path in chapter_meta:
        chapter_text = read_text(path)
        title = first_h1(chapter_text) or f"Chapter {num}: {slug_phrase(path.stem).title()}"
        lines.append(f"{num}. [{title}]({filename})")
    block = "\n".join(lines)
    updated = index_text.rstrip() + "\n\n" + block + "\n"
    return updated, True


def ensure_index_source_refs(index_text: str) -> tuple[str, bool]:
    if "## Source References" in index_text:
        return index_text, False

    candidates = extract_github_links(index_text, limit=8)
    if not candidates:
        return index_text, False

    lines = ["## Source References", ""]
    for label, url in candidates:
        lines.append(f"- [{label}]({url})")
    block = "\n".join(lines)
    updated = index_text.rstrip() + "\n\n" + block + "\n"
    return updated, True


def ensure_index_mermaid(index_text: str, tutorial_title: str) -> tuple[str, bool]:
    if "```mermaid" in index_text:
        return index_text, False
    block = f"""## Concept Flow

```mermaid
flowchart TD
    A[Foundations] --> B[Core Abstractions]
    B --> C[Interaction Patterns]
    C --> D[Advanced Operations]
    D --> E[Production Usage]
```
"""
    updated = index_text.rstrip() + "\n\n" + block + "\n"
    return updated, True


def ensure_index_footer(index_text: str) -> tuple[str, bool]:
    if "AI Codebase Knowledge Builder" in index_text:
        return index_text, False
    updated = index_text.rstrip() + "\n\n" + GEN_FOOTER + "\n"
    return updated, True


def ensure_chapter_intro(
    text: str,
    chapter_title: str,
    tutorial_title: str,
) -> tuple[str, bool]:
    lines = text.splitlines()
    h1_idx = None
    for i, line in enumerate(lines):
        if line.startswith("# "):
            h1_idx = i
            break
    if h1_idx is None:
        return text, False

    window = "\n".join(lines[h1_idx + 1 : h1_idx + 40]).lower()
    if "welcome to" in window:
        return text, False

    intro = (
        f"Welcome to **{chapter_title}**. In this part of **{tutorial_title}**, "
        "you will build an intuitive mental model first, then move into concrete "
        "implementation details and practical production tradeoffs."
    )
    insertion = ["", intro, ""]
    updated_lines = lines[: h1_idx + 1] + insertion + lines[h1_idx + 1 :]
    return "\n".join(updated_lines).rstrip() + "\n", True


def ensure_problem_section(text: str, chapter_title: str, tutorial_slug: str) -> tuple[str, bool]:
    if "## What Problem Does This Solve?" in text:
        return text, False
    block = f"""## What Problem Does This Solve?

Think of this chapter as one subsystem in a larger machine: if this subsystem is unclear, teams build fragile workflows and spend extra time debugging behavior they cannot predict.

This chapter solves that by giving you:

- a clear map of responsibilities and boundaries
- practical rules for deciding what belongs in this layer
- repeatable implementation patterns you can apply in real projects
- failure modes to anticipate before they hurt delivery timelines
"""
    updated = text.rstrip() + "\n\n" + block + "\n"
    return updated, True


def ensure_under_hood_section(text: str, chapter_title: str) -> tuple[str, bool]:
    if "## How it Works Under the Hood" in text:
        return text, False
    block = f"""## How it Works Under the Hood

At runtime, this chapter's system behavior typically follows a predictable lifecycle:

1. **Input acquisition**: collect user intent, configuration, and execution context.
2. **Validation and normalization**: enforce schema constraints and defaults.
3. **Execution orchestration**: route requests through the correct abstraction boundary.
4. **State transitions**: persist or cache critical state for continuity.
5. **Output handling**: return results with error metadata and observability hooks.
6. **Operational safeguards**: enforce retries, backoff, and rollback triggers when needed.

Use this lifecycle as your debugging checklist whenever behavior diverges from expectations.
"""
    updated = text.rstrip() + "\n\n" + block + "\n"
    return updated, True


def ensure_source_walkthrough(
    text: str,
    source_links: list[tuple[str, str]],
) -> tuple[str, bool]:
    if "## Source Walkthrough" in text:
        return text, False

    lines = ["## Source Walkthrough", ""]
    if source_links:
        lines.append("Use these upstream sources for deeper validation and implementation detail:")
        lines.append("")
        for label, url in source_links:
            lines.append(f"- [{label}]({url})")
    else:
        lines.append("Source references are defined in the tutorial index and should be reviewed before production rollout.")

    block = "\n".join(lines)
    updated = text.rstrip() + "\n\n" + block + "\n"
    return updated, True


def ensure_chapter_connections(
    text: str,
    tutorial_dir: Path,
    chapter_meta: list[tuple[int, str, Path]],
    current_idx: int,
) -> tuple[str, bool]:
    if "## Chapter Connections" in text:
        return text, False

    _, current_filename, _ = chapter_meta[current_idx]
    prev_link = None
    next_link = None
    if current_idx > 0:
        _, prev_filename, prev_path = chapter_meta[current_idx - 1]
        prev_title = first_h1(read_text(prev_path)) or prev_filename
        prev_link = (prev_title, prev_filename)
    if current_idx + 1 < len(chapter_meta):
        _, next_filename, next_path = chapter_meta[current_idx + 1]
        next_title = first_h1(read_text(next_path)) or next_filename
        next_link = (next_title, next_filename)

    lines = ["## Chapter Connections", "", f"- [Tutorial Index]({INDEX_NAME})"]
    if prev_link:
        lines.append(f"- [Previous Chapter: {prev_link[0]}]({prev_link[1]})")
    if next_link:
        lines.append(f"- [Next Chapter: {next_link[0]}]({next_link[1]})")
    lines.extend(
        [
            "- [Main Catalog](../../README.md#-tutorial-catalog)",
            "- [A-Z Tutorial Directory](../../discoverability/tutorial-directory.md)",
        ]
    )

    block = "\n".join(lines)
    updated = text.rstrip() + "\n\n" + block + "\n"
    return updated, True


def process_tutorial_dir(tutorial_dir: Path) -> tuple[int, int]:
    changed_files = 0
    examined_files = 0

    index_path = tutorial_dir / INDEX_NAME
    if not index_path.is_file():
        return changed_files, examined_files

    index_text = read_text(index_path)
    tutorial_title = first_h1(index_text) or slug_phrase(tutorial_dir.name).title()
    chapters = chapter_records(tutorial_dir)

    idx_changed = False
    for fn in (
        lambda text: ensure_index_chapter_map(text, tutorial_dir, chapters),
        ensure_index_source_refs,
        lambda text: ensure_index_mermaid(text, tutorial_title),
        ensure_index_footer,
    ):
        index_text, changed = fn(index_text)
        idx_changed = idx_changed or changed
    if idx_changed:
        write_text(index_path, index_text)
        changed_files += 1
    examined_files += 1

    source_links = extract_links_from_heading(index_text, "## Source References", limit=8)
    if not source_links:
        source_links = extract_github_links(index_text, limit=8)

    for i, (_, _, chapter_path) in enumerate(chapters):
        text = read_text(chapter_path)
        chapter_title = first_h1(text) or slug_phrase(chapter_path.stem).title()
        chapter_changed = False

        for fn in (
            lambda t: ensure_chapter_intro(t, chapter_title, tutorial_title),
            lambda t: ensure_problem_section(t, chapter_title, tutorial_dir.name),
            lambda t: ensure_under_hood_section(t, chapter_title),
            lambda t: ensure_source_walkthrough(t, source_links),
            lambda t: ensure_chapter_connections(t, tutorial_dir, chapters, i),
        ):
            text, changed = fn(text)
            chapter_changed = chapter_changed or changed

        if chapter_changed:
            write_text(chapter_path, text)
            changed_files += 1
        examined_files += 1

    return changed_files, examined_files


def main() -> int:
    parser = argparse.ArgumentParser(description="Apply PocketFlow style pass to tutorial docs")
    parser.add_argument("--root", default=".", help="Repository root")
    args = parser.parse_args()

    root = Path(args.root).resolve()
    tutorials_root = root / "tutorials"

    total_changed = 0
    total_examined = 0
    tutorial_count = 0

    for tutorial_dir in sorted(p for p in tutorials_root.iterdir() if p.is_dir()):
        changed, examined = process_tutorial_dir(tutorial_dir)
        total_changed += changed
        total_examined += examined
        if examined:
            tutorial_count += 1

    print(f"tutorials_processed={tutorial_count}")
    print(f"files_examined={total_examined}")
    print(f"files_changed={total_changed}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
