---
layout: default
title: "Chapter 5: Benchmarking and Evaluation Practices"
nav_order: 5
parent: SWE-agent Tutorial
---

# Chapter 5: Benchmarking and Evaluation Practices

This chapter maps SWE-agent usage to benchmark-grade evaluation habits.

## Learning Goals

- measure quality across repeated runs
- compare configurations fairly
- analyze failure classes and regressions
- convert insights into config improvements

## Evaluation Guidance

- keep benchmark inputs stable across comparisons
- log run metadata and model versions per experiment
- review partial successes, not only pass/fail outcomes
- track regressions after tool/model changes

## Source References

- [SWE-agent Usage: Batch Mode](https://swe-agent.com/latest/usage/batch_mode/)
- [SWE-bench Repository](https://github.com/SWE-bench/SWE-bench)
- [SWE-agent README: Positioning and Benchmarks](https://github.com/SWE-agent/SWE-agent/blob/main/README.md)

## Summary

You now have a repeatable framework for benchmarking SWE-agent systems.

Next: [Chapter 6: Offensive Security Mode and Specialized Workloads](06-offensive-security-mode-and-specialized-workloads.md)
